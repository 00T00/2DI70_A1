{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2DI70 Statistical Learning Theory \n",
    "## Assignment 1\n",
    "\n",
    "### Group x\n",
    "Name1 ID1\n",
    "\n",
    "Name2 ID2\n",
    "\n",
    "Name3 ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import numpy as np\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST data from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small = pd.read_csv(\"MNIST_train_small.csv\").values\n",
    "test_small  = pd.read_csv(\"MNIST_test_small.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing the data is probably not necessary for this specific dataset\n",
    "X_train_s = train_small[:, 1:]/255.0\n",
    "y_train_s = train_small[:,0]\n",
    "\n",
    "X_test_s = test_small[:, 1:]/255.0\n",
    "y_test_s = test_small[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Render chosen data point as image\n",
    "def show_img(data, index):\n",
    "    plt.imshow(data[index].reshape(28,28), cmap = \"Greys\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.617445178210408\n"
     ]
    }
   ],
   "source": [
    "## Compute the nth root of given value\n",
    "def n_root(val, p):   \n",
    "    return val**(1 / float(p))\n",
    "  \n",
    "## Compute Minkowski distance for two given vectors\n",
    "## Use p = 2 for Euclidian distance\n",
    "def minkowski_dist(x1, x2, p):    \n",
    "    p_sum = sum(pow(abs(a-b), p) for a, b in zip(x1, x2))\n",
    "    return n_root(p_sum, p) \n",
    "  \n",
    "v1 = X_train_s[0]\n",
    "v2 = X_train_s[1]\n",
    "print(minkowski_dist(v1, v2, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute p-minkowski distance from point to every datapoint in collection\n",
    "## The list of labels should share length and indices with collection\n",
    "def compute_dists(point, collection, labels, p):\n",
    "    vals = []\n",
    "    for i in range(len(collection)):\n",
    "        d = minkowski_dist(point, collection[i], p)\n",
    "        vals.append([i, d, labels[i]])\n",
    "    \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do KNN magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Compute knn for example data\n",
    "show_img(X_test_s, 0)\n",
    "dists1 = compute_dists(X_test_s[0], X_train_s, y_train_s, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1135, 5.3865168364513, 2],\n",
       " [2930, 6.176237779614883, 2],\n",
       " [1839, 6.359115856708896, 2],\n",
       " [2931, 6.971545396350763, 2],\n",
       " [1673, 7.1679066012479415, 2],\n",
       " [1745, 7.241429992960301, 2],\n",
       " [674, 7.360805206442928, 2],\n",
       " [1959, 7.46974314606631, 2],\n",
       " [2869, 7.472301795139638, 2],\n",
       " [1058, 7.590140106469208, 2],\n",
       " [394, 7.816389685297066, 2],\n",
       " [20, 7.866137843152389, 2],\n",
       " [535, 7.8670723020162905, 2],\n",
       " [1936, 7.948569785196725, 2],\n",
       " [1146, 7.982502009483685, 2],\n",
       " [402, 8.022200070046882, 2],\n",
       " [2694, 8.041375128432373, 2],\n",
       " [1943, 8.087366085202186, 2],\n",
       " [629, 8.16194129232512, 2],\n",
       " [2707, 8.167651236462792, 2]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Since the point we selected is in the training set, it shows up in the list with a distance of 0\n",
    "## In this case, we can confidently say it is a 3\n",
    "dists1_sorted = sorted(dists1, key = lambda x: float(x[1]))\n",
    "dists1_sorted[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1135, 5.3865168364513, 2], [2930, 6.176237779614883, 2], [1839, 6.359115856708896, 2], [2931, 6.971545396350763, 2], [1673, 7.1679066012479415, 2], [1745, 7.241429992960301, 2], [674, 7.360805206442928, 2], [1959, 7.46974314606631, 2], [2869, 7.472301795139638, 2], [1058, 7.590140106469208, 2], [394, 7.816389685297066, 2], [20, 7.866137843152389, 2], [535, 7.8670723020162905, 2], [1936, 7.948569785196725, 2], [1146, 7.982502009483685, 2], [402, 8.022200070046882, 2], [2694, 8.041375128432373, 2], [1943, 8.087366085202186, 2], [629, 8.16194129232512, 2], [2707, 8.167651236462792, 2]]\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "predicted label is:2.0\n",
      "actual label is: 2\n",
      "[[666, 2.247698639363126, 1], [1556, 2.5222881905648644, 1], [2272, 2.9979924078470668, 1], [2205, 3.3107725559662793, 1], [207, 3.412974768508096, 1], [460, 3.58639618571662, 1], [1410, 3.604725848508672, 1], [292, 3.7451575808838355, 1], [2018, 4.11309178468212, 1], [1284, 4.1317201152923095, 1], [2376, 4.18657343837898, 1], [1412, 4.2582728131272685, 1], [619, 4.337134345734389, 1], [927, 4.357787445331074, 1], [861, 4.4211386252367335, 1], [232, 4.508970084892044, 1], [1842, 4.572168954708879, 1], [58, 4.638438268775499, 1], [1818, 4.756241978149315, 1], [2986, 4.769165991262066, 1]]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "predicted label is:1.0\n",
      "actual label is: 1\n",
      "[[706, 5.913981634854253, 3], [480, 6.581187874019491, 3], [1286, 6.800288344520949, 3], [1703, 6.871073937528168, 8], [1389, 6.99820705329475, 3], [2476, 7.037767069250759, 3], [451, 7.080177938886135, 8], [2259, 7.099817781720941, 8], [1080, 7.110279771666691, 0], [1017, 7.197239848574488, 0], [690, 7.234661750355772, 8], [1659, 7.281282191863933, 0], [2189, 7.311077689238803, 0], [918, 7.31308203025496, 3], [1952, 7.466583250481485, 0], [1438, 7.535849984344409, 3], [1125, 7.552148065784697, 0], [2268, 7.5550828718867535, 3], [291, 7.5594895563749, 5], [796, 7.579364526675045, 0]]\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "8\n",
      "8\n",
      "0\n",
      "0\n",
      "8\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "predicted label is:3.05\n",
      "actual label is: 3\n"
     ]
    }
   ],
   "source": [
    " for i in range (3): # range(len(X_test_s)):\n",
    "    dists1 = compute_dists(X_test_s[i], X_train_s, y_train_s, 2)\n",
    "    dists1_sorted = sorted(dists1, key = lambda x: float(x[1]))\n",
    "    list = dists1_sorted[0:20] #get top 20 nearest neighbors \n",
    "      \n",
    "    ## here we get the label of closest neighbors\n",
    "    print (list)\n",
    "    labels = {}\n",
    "    current_sum_labels = 0;\n",
    "    for j in range(len(list)):\n",
    "        labels = (list[j][-1]) \n",
    "        print(labels)\n",
    "        current_sum_labels = current_sum_labels + labels\n",
    "    pred = 0 \n",
    "    pred = current_sum_labels/len(list)\n",
    "    print (\"predicted label is:\" + str(pred))\n",
    "    print (\"actual label is: \" + str(y_test_s[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class is: 2\n",
      "Actual class is: 2\n",
      "Total error is: 0.0\n",
      "Predicted class is: 1\n",
      "Actual class is: 1\n",
      "Total error is: 0.0\n",
      "Predicted class is: 3\n",
      "Actual class is: 3\n",
      "Total error is: 0.0\n",
      "Predicted class is: 9\n",
      "Actual class is: 9\n",
      "Total error is: 0.0\n",
      "Predicted class is: 1\n",
      "Actual class is: 1\n",
      "Total error is: 0.0\n",
      "Predicted class is: 4\n",
      "Actual class is: 4\n",
      "Total error is: 0.0\n",
      "Predicted class is: 2\n",
      "Actual class is: 2\n",
      "Total error is: 0.0\n",
      "Predicted class is: 6\n",
      "Actual class is: 6\n",
      "Total error is: 0.0\n",
      "Predicted class is: 3\n",
      "Actual class is: 3\n",
      "Total error is: 0.0\n",
      "Predicted class is: 7\n",
      "Actual class is: 7\n",
      "Total error is: 0.0\n",
      "Predicted class is: 4\n",
      "Actual class is: 4\n",
      "Total error is: 0.0\n",
      "Predicted class is: 9\n",
      "Actual class is: 9\n",
      "Total error is: 0.0\n",
      "Predicted class is: 0\n",
      "Actual class is: 0\n",
      "Total error is: 0.0\n",
      "Predicted class is: 6\n",
      "Actual class is: 6\n",
      "Total error is: 0.0\n",
      "Predicted class is: 7\n",
      "Actual class is: 7\n",
      "Total error is: 0.0\n",
      "Predicted class is: 6\n",
      "Actual class is: 6\n",
      "Total error is: 0.0\n",
      "Predicted class is: 7\n",
      "Actual class is: 7\n",
      "Total error is: 0.0\n",
      "Predicted class is: 9\n",
      "Actual class is: 9\n",
      "Total error is: 0.0\n",
      "Predicted class is: 9\n",
      "Actual class is: 9\n",
      "Total error is: 0.0\n",
      "Predicted class is: 0\n",
      "Actual class is: 2\n",
      "Total error is: 0.05\n"
     ]
    }
   ],
   "source": [
    "#for each x in test set, compute the distance with all x in training set, then sort in distance for top 20 nearest neighbors\n",
    "for i in range (20): # range(len(X_test_s)):\n",
    "    dists = compute_dists(X_test_s[i], X_train_s, y_train_s, 2)\n",
    "    dists_sorted = sorted(dists, key = lambda x: float(x[1]))\n",
    "    list = dists_sorted[0:20] #get list top 20 nearest neighbors with its [index,distance,label] \n",
    "     \n",
    "#count frequency of labels of the top 20 nearest neighbors\n",
    "    pred_class = {}\n",
    "    for j in range(20):\n",
    "        labels = list[j][-1]\n",
    "        if labels in pred_class:\n",
    "            pred_class[labels] += 1\n",
    "        else:\n",
    "            pred_class[labels] = 1\n",
    "#sort the most frequency labels at the beginning, return the prediction as the most frequency label at first position\n",
    "    sortedVotes = sorted(pred_class.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    print(\"Predicted class is: \" + str(sortedVotes[0][0]))\n",
    "    print (\"Actual class is: \" + str(y_test_s[i]))\n",
    "    error = 0\n",
    "    if sortedVotes[0][0] != y_test_s[i]:\n",
    "        error = error + 1\n",
    "    print(\"Total error is: \" + str(error/20))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
